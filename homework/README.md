# Study-practic3
1.1 Сравнение моделей разной глубины:
- 1 слой (линейный классификатор)
train accuracy постпенно возрастет, а test accuracy изначально выше train, но затем обваливается. На train данных модель обучается за 16-17 сек, а на реальных в 8 раз быстрее.
- 2 слоя (1 скрытый)
train accuracy постпенно возрастет, test accuracy изначально выше train, но рост не такой заметный. На train данных модель обучается за 16-17 сек, а на реальных в 8 раз быстрее.
- 3 слоя (2 скрытых)
train accuracy постпенно возрастет, рост test accuracy незначителен, к третьей эпохе train обогнала test. На train данных модель обучается в среднем за 20 сек, а на реальных в ~7 раз быстрее.
- 5 слоев (4 скрытых)
Обе функции возрастют. На train данных модель обучается в среднем за 30 сек, а на реальных в ~10 раз быстрее.
- 7 слоев (6 скрытых)
Обе функции возрастют, но рост test accuracy незначителен, к пятой эпохе train обогнала test. На train данных модель обучается в среднем за 20 сек, а на реальных в ~10 раз быстрее.

Получается, что на train данных с увеличением глубины обучение занимает больше времени, в то время как на test данных обучение стабильно занимает по 2-3 сек вне зависимости от глубины

1.2 Анализ переобучения
Для датасетов MNIST и QMNIST оптимальная глубина - 1, так как значение accuracy при этом самое высокое. С Dropout и BatchNorm значение accuracy на test данных выше на обоих датасетах, на втором рост этой функции стал более стабильным. На обоих датасетах при двух слоях наблюдаетя обвал на test данных, что может свидетельствовать о переобучении.

2.1 Сравнение моделей разной ширины:
- Узкие слои: [64, 32, 16]
train accuracy постпенно возрастет, test accuracy колеблется. На train данных модель обучается в среднем за 11 сек, а на реальных в ~10 раз быстрее. Количество параметров: 53018.
- Средние слои: [256, 128, 64]
train accuracy постпенно возрастет, test accuracy колеблется. На train данных модель обучается в среднем за 18 сек, а на реальных в ~9 раз быстрее. Количество параметров: 242762.
- Широкие слои: [1024, 512, 256]
train accuracy постпенно возрастет, test accuracy возрастает с колебаниями. На train данных модель обучается в среднем за 20 сек, а на реальных в ~20 раз быстрее. Количество параметров: 1462538.
- Очень широкие слои: [2048, 1024, 512]
train accuracy постпенно возрастет, test accuracy обвалилась на третьей эпохе. На train данных модель обучается в среднем за 1 мин, а на реальных в ~12 раз быстрее. Количество параметров: 4235786.

Получается, что количество параметров с увеличением ширины слоев увеличиваются в несколько раз

